{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed680c3-5036-48a9-888d-5aa50da3e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50, EfficientNetB0\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7968bb76-2183-4328-8001-bc6642c6bd8b",
   "metadata": {},
   "source": [
    "# Verify Dataset Programmatically (Before Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde02be5-b6d9-439e-904a-8438888be9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATASET_DIR = r\"C:\\Users\\LENOVO P14S\\6th-Sem-Project\\dataset\"\n",
    "\n",
    "classes = os.listdir(DATASET_DIR)\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "for cls in classes:\n",
    "    cls_path = os.path.join(DATASET_DIR, cls)\n",
    "    print(f\"{cls}: {len(os.listdir(cls_path))} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891d6c19-cd3e-424b-8c76-287a8825bc13",
   "metadata": {},
   "source": [
    "# Load Images the RIGHT Way\n",
    "#### This alone: Labels your data\n",
    "#### Splits train/validation\n",
    "#### Resizes images\n",
    "#### Builds an efficient pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9281670-f5f9-43c5-a3ec-499b16ce8b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATASET_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=42,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATASET_DIR,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=42,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Class names:\", class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f3fdd-93d6-42aa-a482-1dc3f1b8d359",
   "metadata": {},
   "source": [
    "# Normalize Images\n",
    "### Neural networks do not like raw pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b5cb1-37a9-46bf-a705-5a0e12cb3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d54452a-1a96-40f9-876f-d17bf9cef762",
   "metadata": {},
   "source": [
    "# Visual Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa296274-9f3d-4c64-8ee6-7a4d73223227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a1bd7-4f45-4e01-9874-8f37228695eb",
   "metadata": {},
   "source": [
    "# Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f92e6e-a41f-46ad-aad5-0289bd9acb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {\n",
    "    0: 629 / 388,   # ripen\n",
    "    1: 1.0          # unripen\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b22b07-d283-403e-948b-b632bcc0d5c3",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a10c92-1010-4a77-a808-83f7cd80f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780bab99-e923-4aa9-856f-1282451adbb3",
   "metadata": {},
   "source": [
    "# Build the Model\n",
    "### Step 1: Load Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2a0df2-67f5-4d2f-a1a3-09d95ec7a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1279d4-8c30-470f-846b-72d31c903e91",
   "metadata": {},
   "source": [
    "### Step 2: Custom Classification Head \n",
    "#### Binary problem â†’ sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d2b457-0721-4982-b773-401397f6cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5b653c-6abc-4486-a8ba-21645e4f5b3e",
   "metadata": {},
   "source": [
    "### Step 3: Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f047e49-7bdb-4ceb-9d2b-7056dcbbf217",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\",\"precision\",\"Recall\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001cebad-aa82-4897-a8bc-db3c9845abc6",
   "metadata": {},
   "source": [
    "# Train (Phase 1: Feature Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc15ccb-a2f1-4b51-88dc-09f1d53c2c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d6623f-f151-41ec-825f-289e144fdeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba68d8f-758a-4a0b-a910-40a7814ee6cf",
   "metadata": {},
   "source": [
    "# CONFUSION MATRIX\n",
    "### Step 1: Collect true labels and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccd17f8-0931-4c76-8005-34b2d9c50e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    preds = model.predict(images)\n",
    "    preds = (preds > 0.5).astype(int).flatten()\n",
    "\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced35e8-7881-40c7-8ac0-047367ce3b8e",
   "metadata": {},
   "source": [
    "### Step 2: Generate confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7606a7d2-abb8-4aa5-af64-b31a927ae66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "            xticklabels=[\"Ripen\", \"Unripen\"],\n",
    "            yticklabels=[\"Ripen\", \"Unripen\"],\n",
    "            cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68138923-612e-4503-8e27-a67c1122ee20",
   "metadata": {},
   "source": [
    "# PRECISION, RECALL, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b5550b-2f81-4755-9b55-948208aee68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=[\"Ripen\", \"Unripen\"]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b4b3aa-e948-4cae-ab2c-bed4549f699d",
   "metadata": {},
   "source": [
    "# FINAL MODEL SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf951a9-8cc4-4f5f-aa9a-27798205ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"arecanut_maturity.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ef690-d77c-4b91-9fbf-6cdf04c01caf",
   "metadata": {},
   "source": [
    "# TENSORFLOW LITE CONVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd724f-7a82-476a-a730-a81e804390ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"arecanut_maturity.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0119d-53e1-4335-823c-3ea975af274d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
